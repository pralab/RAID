# RAID
Source code for the paper "RAID: A Dataset for Testing the Adversarial
Robustness of AI-Generated Image Detectors"

## Licenses
The provided MIT License only applies to the `raid` directory. The code
contained in the `external` folder, provided by third-parties and modified in
some parts, has its own licenses that are included in each subfolder.

### External repositories

#### Cavia et al., Real-Time Deepfake Detection in the Real-World.<br>[Repository](https://github.com/barcavia/RealTime-DeepfakeDetection-in-the-RealWorld)&nbsp;&nbsp;&nbsp;&nbsp;[Paper](https://arxiv.org/abs/2406.09398)
#### Chen et al., DRCT: Diffusion reconstruction contrastive training towards universal detection of diffusion generated images.<br>[Repository](https://github.com/beibuwandeluori/DRCT)&nbsp;&nbsp;&nbsp;&nbsp;[Paper](https://raw.githubusercontent.com/mlresearch/v235/main/assets/chen24ay/chen24ay.pdf)
#### Corvi et al., On the detection of synthetic images generated by diffusion models.<br>[Repository](https://github.com/grip-unina/DMimageDetection)&nbsp;&nbsp;&nbsp;&nbsp;[Paper](https://arxiv.org/abs/2211.00680)
#### Koutlis and Papadopoulos, Leveraging representations from intermediate encoder-blocks for synthetic image detection.<br>[Repository](https://github.com/mever-team/rine)&nbsp;&nbsp;&nbsp;&nbsp;[Paper](https://arxiv.org/abs/2402.19091)
#### Ojha et al., Towards Universal Fake Image Detectors that Generalize Across Generative Models.<br>[Repository](https://github.com/WisconsinAIVision/UniversalFakeDetect)&nbsp;&nbsp;&nbsp;&nbsp;[Paper](https://arxiv.org/abs/2302.10174)
#### Wang et al., CNN-generated images are surprisingly easy to spot...for now.<br>[Repository](https://github.com/PeterWang512/CNNDetection)&nbsp;&nbsp;&nbsp;&nbsp;[Paper](https://arxiv.org/abs/1912.11035)